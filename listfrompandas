import json

import requests
import urllib.request
import urllib
import os
import os.path
import threading
from queue import Queue


apikey= "a66325f81b70da9ac277c027cf9e7371"
# hi= "a66325f81b70da9ac277c027cf9e7371"+"Secret: 49453dbf41f087e0"
q = Queue()
writinglock = threading.Lock()

#number of pictures returned per page
perpage = 100


#main function with three paramenters, automatically downloads pictures with searched term into folder with set filepath.
def main(searchterm,amount=10, path=''):
    pagenumber = 1
    counter = 0
    apiurl = "https://api.flickr.com/services/rest/" \
         "?method=flickr.photos.search&api_key="+apikey+\
             "&text="+searchterm+"&per_page="+str(perpage)+"&page"+str(pagenumber)+"&format=json&nojsoncallback=1"
    response = requests.get(apiurl)
    response = response.json()



    if path != "":
        filepath = os.path.relpath(path,os.getcwd()+os.sep+searchterm)+os.sep+searchterm
    else:
        filepath = searchterm
    if not os.path.exists(filepath):
        os.makedirs(filepath)


    if response.get("stat")=='ok':
        response = response.get("photos")
        total = int(response.get('total'))
        if total > 4000 and amount > 4000:
            print('flickr only allows for max 4000 image retrieval,saving first 4000')
            toparse = 4000
        elif total < amount:
            toparse = total
            print('not enought image found, saving existing'+response.get('total')+"images")
        else:
            toparse = amount
        while toparse - perpage > -perpage:
            apiurl = "https://api.flickr.com/services/rest/" \
                     "?method=flickr.photos.search&api_key=" + apikey + \
                     "&text=" + searchterm + "&per_page=" + str(perpage) + "&page" + str(pagenumber) + "&format=json&nojsoncallback=1"
            response = requests.get(apiurl).json().get('photos')
            photolist = response.get('photo')
            actual_perpage=len(photolist)

            for x in range(0,actual_perpage):
                q.put((photolist[x].get('id'), filepath + os.sep + searchterm + str(counter)))
                counter += 1

            # wait until the thread terminates.
            toparse = toparse-actual_perpage
            for x in range(10):
                t = threading.Thread(target=threader)

                # classifying as a daemon, so they will die when the main dies
                t.daemon = True

                # begins, must come after daemon definition
                t.start()
            pagenumber += 1



        q.join()
        print('done')

def downloadimg(photo_id,name=''):
#downloads the image in largest resolution and marked as downloadable
    photo_id=str(photo_id)
    rqurl = "https://api.flickr.com/services/rest/" \
         "?method=flickr.photos.getSizes&api_key=" +apikey+\
            "&photo_id="+photo_id+"&per_page=100&format=json&nojsoncallback=1"

    response = requests.get(rqurl).json()

    if response.get('stat')=='ok':
        response= response.get('sizes')

        if response.get("candownload") == 1:
            #gets the best quality, as list sorted in increasing resolution
            url = response.get('size')[0].get('source')
            print(url)

            with writinglock:
                urllib.request.urlretrieve(url, name+'.jpg')

def threader():
    while True:
        worker = q.get()
        downloadimg(worker[0],worker[1])
        q.task_done()

main('pig', 350, 'pictures/test')


